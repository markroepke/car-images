{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Car Make with CNNs\n",
    "\n",
    "## Overview\n",
    "\n",
    "The purpose of this notebook is self-learning. It's an attempt to predict car manufacturer using a convolutional neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "TensorFlow 2 will be used to build the neural network, and it will be accessed via the Keras front-end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from PIL import Image\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import backend\n",
    "from keras import optimizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir('/Users/markroepke/Documents/fun/projects/car-images/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep\n",
    "\n",
    "The entire data set is made up of 64,000 images of cars from [thecarconnection.com](). It was originally sourced by Nicolas Gervais, and details can be found on his Reddit post: https://www.reddit.com/r/MachineLearning/comments/ek5zwv/p_64000_pictures_of_cars_labeled_by_make_model/.\n",
    "\n",
    "For now, the data is not cross-validated so it's simply split into training, validating, and testing data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 0 photos, 0%\n",
      "Finished 6447 photos, 10%\n"
     ]
    }
   ],
   "source": [
    "# Load and randomize all image file names\n",
    "full_image_paths = glob(\"data/full-images/*.jpg\")\n",
    "full_image_paths = np.random.permutation(full_image_paths)\n",
    "\n",
    "# Process each image and its label\n",
    "scaled_images = []\n",
    "makes = []\n",
    "for idx, image_path in enumerate(full_image_paths):\n",
    "    if idx > 10000:\n",
    "        break\n",
    "        \n",
    "    # Resize each image to 256x256 and convert it to grayscale\n",
    "    processed_image = Image.open(image_path).resize((256, 256)).convert('L')\n",
    "    scaled_images.append(np.array(processed_image))\n",
    "    \n",
    "    # Get the make of the car from the file name\n",
    "    makes.append(image_path.split(\"/\")[2].split(\"_\")[0])\n",
    "    \n",
    "    # Print update as this can take a little while\n",
    "    if idx % round(len(full_image_paths) / 10) == 0:\n",
    "        print(f\"Finished {idx} photos, {round((idx / len(full_image_paths)) * 100)}%\")\n",
    "        \n",
    "# Rescale images for keras/tensorflow\n",
    "scaled_images_array = np.array(scaled_images)\n",
    "scaled_images_array = scaled_images_array.reshape(\n",
    "    scaled_images_array.shape[0], \n",
    "    scaled_images_array.shape[1], \n",
    "    scaled_images_array.shape[2],\n",
    "    1\n",
    ")\n",
    "\n",
    "# Get number of distant labels present in data set\n",
    "distinct_y = len(set(list(makes)))\n",
    "\n",
    "# Transform labels for keras/tensorflow\n",
    "encoder = LabelBinarizer()\n",
    "makes_array = encoder.fit_transform(np.array(makes))\n",
    "\n",
    "# Create x datasets\n",
    "train_x = scaled_images_array[:round(0.7 * len(scaled_images_array))]\n",
    "val_x = scaled_images_array[round(0.7 * len(scaled_images_array)):round(0.9 * len(scaled_images_array))]\n",
    "holdout_x = scaled_images_array[round(0.9 * len(scaled_images_array)):]\n",
    "\n",
    "# Create y datasets\n",
    "train_y = makes_array[:round(0.7 * len(makes_array))]\n",
    "val_y = makes_array[round(0.7 * len(makes_array)):round(0.9 * len(makes_array))]\n",
    "holdout_y = makes_array[round(0.9 * len(makes_array)):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7001 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "7001/7001 [==============================] - 291s 42ms/step - loss: 0.2709 - acc: 0.9697 - val_loss: 0.2309 - val_acc: 0.9533\n",
      "Epoch 2/10\n",
      "7001/7001 [==============================] - 288s 41ms/step - loss: 0.1047 - acc: 0.9760 - val_loss: 0.1235 - val_acc: 0.9684\n",
      "Epoch 3/10\n",
      "7001/7001 [==============================] - 289s 41ms/step - loss: 0.0786 - acc: 0.9786 - val_loss: 0.1880 - val_acc: 0.9564\n",
      "Epoch 4/10\n",
      "7001/7001 [==============================] - 289s 41ms/step - loss: 0.0497 - acc: 0.9848 - val_loss: 0.2366 - val_acc: 0.9586\n",
      "Epoch 5/10\n",
      "7001/7001 [==============================] - 311s 44ms/step - loss: 0.0279 - acc: 0.9912 - val_loss: 0.1873 - val_acc: 0.9655\n",
      "Epoch 6/10\n",
      "7001/7001 [==============================] - 288s 41ms/step - loss: 0.0152 - acc: 0.9954 - val_loss: 0.1566 - val_acc: 0.9756\n",
      "Epoch 7/10\n",
      "7001/7001 [==============================] - 299s 43ms/step - loss: 0.0091 - acc: 0.9975 - val_loss: 0.1948 - val_acc: 0.9766\n",
      "Epoch 8/10\n",
      "7001/7001 [==============================] - 307s 44ms/step - loss: 0.0059 - acc: 0.9986 - val_loss: 0.2410 - val_acc: 0.9784\n",
      "Epoch 9/10\n",
      "7001/7001 [==============================] - 295s 42ms/step - loss: 0.0042 - acc: 0.9990 - val_loss: 0.2445 - val_acc: 0.9779\n",
      "Epoch 10/10\n",
      "7001/7001 [==============================] - 305s 44ms/step - loss: 0.0028 - acc: 0.9993 - val_loss: 0.2450 - val_acc: 0.9778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x19d391f28>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear TensorFlow session for iterative development\n",
    "backend.clear_session()\n",
    "\n",
    "# Build convolutional layers for vision\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape = (256, 256, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten convolutional output and condense into predictions\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation = 'relu'))\n",
    "model.add(layers.Dense(distinct_y, activation = 'softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = optimizers.RMSprop(lr=1e-4), metrics = ['acc'])\n",
    "\n",
    "# Train model\n",
    "model.fit(x = train_x, y = train_y, epochs = 10, batch_size = 50, validation_data = (val_x, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on Holdout Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on a true holdout set for final performance metric --> about 98% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 12s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "holdout_loss, holdout_acc = model.evaluate(holdout_x, holdout_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9771905541419983"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
