{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Car Make with CNNs\n",
    "\n",
    "## Overview\n",
    "\n",
    "The purpose of this notebook is self-learning. It's an attempt to predict car manufacturer using a convolutional neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "TensorFlow 2 will be used to build the neural network, and it will be accessed via the Keras front-end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from PIL import Image\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import backend\n",
    "from keras import optimizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir('/home/ubuntu/car-images/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep\n",
    "\n",
    "The entire data set is made up of 64,000 images of cars from [thecarconnection.com](). It was originally sourced by Nicolas Gervais, and details can be found on his Reddit post: https://www.reddit.com/r/MachineLearning/comments/ek5zwv/p_64000_pictures_of_cars_labeled_by_make_model/.\n",
    "\n",
    "For now, the data is not cross-validated so it's simply split into training, validating, and testing data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 0 photos, 0%\n",
      "Finished 6447 photos, 10%\n",
      "Finished 12894 photos, 20%\n",
      "Finished 19341 photos, 30%\n",
      "Finished 25788 photos, 40%\n",
      "Finished 32235 photos, 50%\n",
      "Finished 38682 photos, 60%\n",
      "Finished 45129 photos, 70%\n",
      "Finished 51576 photos, 80%\n",
      "Finished 58023 photos, 90%\n"
     ]
    }
   ],
   "source": [
    "# Load and randomize all image file names\n",
    "full_image_paths = glob(\"data/full-images/*.jpg\")\n",
    "full_image_paths = np.random.permutation(full_image_paths)\n",
    "\n",
    "# Process each image and its label\n",
    "scaled_images = []\n",
    "makes = []\n",
    "for idx, image_path in enumerate(full_image_paths):\n",
    "        \n",
    "    # Resize each image to 256x256 and convert it to grayscale\n",
    "    processed_image = Image.open(image_path).resize((100, 100)).convert('L')\n",
    "    scaled_images.append(np.array(processed_image))\n",
    "    \n",
    "    # Get the make of the car from the file name\n",
    "    makes.append(image_path.split(\"/\")[2].split(\"_\")[0])\n",
    "    \n",
    "    # Print update as this can take a little while\n",
    "    if idx % round(len(full_image_paths) / 10) == 0:\n",
    "        print(f\"Finished {idx} photos, {round((idx / len(full_image_paths)) * 100)}%\")\n",
    "        \n",
    "# Rescale images for keras/tensorflow\n",
    "scaled_images_array = np.array(scaled_images)\n",
    "scaled_images_array = scaled_images_array.reshape(\n",
    "    scaled_images_array.shape[0], \n",
    "    scaled_images_array.shape[1], \n",
    "    scaled_images_array.shape[2],\n",
    "    1\n",
    ")\n",
    "\n",
    "# Get number of distant labels present in data set\n",
    "distinct_y = len(set(list(makes)))\n",
    "\n",
    "# Transform labels for keras/tensorflow\n",
    "encoder = LabelBinarizer()\n",
    "makes_array = encoder.fit_transform(np.array(makes))\n",
    "\n",
    "# Create x datasets\n",
    "train_x = scaled_images_array[:round(0.7 * len(scaled_images_array))]\n",
    "val_x = scaled_images_array[round(0.7 * len(scaled_images_array)):round(0.9 * len(scaled_images_array))]\n",
    "holdout_x = scaled_images_array[round(0.9 * len(scaled_images_array)):]\n",
    "\n",
    "# Create y datasets\n",
    "train_y = makes_array[:round(0.7 * len(makes_array))]\n",
    "val_y = makes_array[round(0.7 * len(makes_array)):round(0.9 * len(makes_array))]\n",
    "holdout_y = makes_array[round(0.9 * len(makes_array)):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 45127 samples, validate on 12893 samples\n",
      "Epoch 1/10\n",
      "45127/45127 [==============================] - 301s 7ms/step - loss: 0.2196 - acc: 0.9716 - val_loss: 0.1053 - val_acc: 0.9762\n",
      "Epoch 2/10\n",
      "45127/45127 [==============================] - 300s 7ms/step - loss: 0.1040 - acc: 0.9762 - val_loss: 0.1030 - val_acc: 0.9762\n",
      "Epoch 3/10\n",
      "45127/45127 [==============================] - 300s 7ms/step - loss: 0.1009 - acc: 0.9762 - val_loss: 0.1014 - val_acc: 0.9762\n",
      "Epoch 4/10\n",
      "45127/45127 [==============================] - 302s 7ms/step - loss: 0.0973 - acc: 0.9764 - val_loss: 0.0991 - val_acc: 0.9763\n",
      "Epoch 5/10\n",
      "45127/45127 [==============================] - 301s 7ms/step - loss: 0.0932 - acc: 0.9767 - val_loss: 0.0982 - val_acc: 0.9764\n",
      "Epoch 6/10\n",
      "45127/45127 [==============================] - 302s 7ms/step - loss: 0.0889 - acc: 0.9774 - val_loss: 0.0947 - val_acc: 0.9768\n",
      "Epoch 7/10\n",
      "45127/45127 [==============================] - 301s 7ms/step - loss: 0.0844 - acc: 0.9782 - val_loss: 0.0923 - val_acc: 0.9773\n",
      "Epoch 8/10\n",
      "45127/45127 [==============================] - 300s 7ms/step - loss: 0.0800 - acc: 0.9791 - val_loss: 0.0908 - val_acc: 0.9777\n",
      "Epoch 9/10\n",
      "45127/45127 [==============================] - 299s 7ms/step - loss: 0.0756 - acc: 0.9801 - val_loss: 0.0892 - val_acc: 0.9782\n",
      "Epoch 10/10\n",
      "45127/45127 [==============================] - 298s 7ms/step - loss: 0.0714 - acc: 0.9811 - val_loss: 0.0860 - val_acc: 0.9790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f03d972cef0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear TensorFlow session for iterative development\n",
    "backend.clear_session()\n",
    "\n",
    "# Build convolutional layers for vision\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape = (100, 100, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten convolutional output and condense into predictions\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(200, activation = 'relu'))\n",
    "model.add(layers.Dense(distinct_y, activation = 'softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = optimizers.RMSprop(lr=1e-4), metrics = ['acc'])\n",
    "\n",
    "# Train model\n",
    "model.fit(x = train_x, y = train_y, epochs = 10, batch_size = 200, validation_data = (val_x, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on Holdout Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on a true holdout set for final performance metric --> about 98% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6447/6447 [==============================] - 14s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "holdout_loss, holdout_acc = model.evaluate(holdout_x, holdout_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97913391573107"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
